%!TeX root = thesis-main.tex
\chapter{Platform: Deployment of Cyber-Physical Swarms applications}\label{chap:eng:multitier}%\mtcaddchapter

\begin{flushright}
  \begin{minipage}{0.5\textwidth}
    How can we deploy an aggregate computing application in a large variety of network architectures?

    Does the deployment strategy affect the functional behaviour of the application?

    How can we ensure that the deployment strategy is correct and safe?

    -- \textbf{RQ1, RQ4}    
  \end{minipage}
\end{flushright}

\minitoc% Creating an actual minitoc
%
\newcommand{\scalaloci}{{ScalaLoci}}
\newcommand{\scafiloci}{{ScaFiLoci}}
\newcommand{\scalainline}[1]{\lstinline{#1}}
\ac{cpsw} are typically required 
 to act as coordinated collectives
 and to be able to adapt to dynamic
 environmental conditions and inputs.
%
%
As discussed in \Cref{chap:macro-programming} reliance on a centralized device is not allowed,
and the system is expected to reach global goals based 
 on the coordinated (inter-)actions of the individual entities that compose the system.
Aggregate computing foster the adoption of \emph{global-to-local} techniques,
by which the behaviour of the ensemble of devices is designed top-down,
and interactions among devices (i.e., protocols) are generated automatically and implicitly.
%
However, the generated interaction scheme depends on assumptions about how devices communicate with each other;
in other words, the approach often dictates how the network should be structured.
%
In turn, this creates a tension between the network structure the language reasons upon and the actual way devices communicate.
%
Since in \acp{cpsw} the challenging case in which no controllers exist must typically be supported, 
 a purely \emph{peer-to-peer (P2P)} network is usually considered the paradigmatic setup.
%
However, real-world networks are usually structured hierarchically, 
 and the ability to target multiple infrastructural setups can help to achieve non-functional benefits.
%
Therefore, a contemporary approach designed to facilitate agile deployment of \ac{cpsw} should be versatile enough to accommodate multiple network architectures.
In this direction, \emph{Pulverization}~\cite{DBLP:journals/fi/CasadeiPPVW20}
 is an approach proposed for aggregate computing 
 (but in principle applicable to other frameworks) 
 to neatly separate behavioural and deployment concerns.
%
In short, it decomposes the concept of a \emph{logical device}, 
 which is the target for which the behaviour is programmed,
 into micro-components that can be deployed independently
 and whose internal communication protocol is defined at deployment time.
%
This technique de facto relieves the behaviour designer of the duty 
 to consider multiple possible  deployments in different networks, 
 allowing them to write the behaviour for the most generic case, 
 and have the program \emph{functionally} behave as designed regardless of the actual final deployment.

However, pulverization does not directly provide ways for \emph{specifying} and \emph{deploying} components in a safe and meaningful fashion:
 it proposes a methodology to cleanly separate behavioural and deployment concerns that need to be addressed at some point.
%
The definition of the deployment strategy and its execution is thus a very relevant and challenging engineering issue on its own:
 ideally, such a specification should be declarative
 and possibly guided and checked by static analysis
 to lower the risk of failures at runtime.

This chapter discusses how a pulverized system can be deployed and executed on multiple different network structures,
 by leveraging a recent approach known as \emph{multi-tier programming}~\cite{DBLP:journals/csur/WeisenburgerWS20}.
%
In multi-tier programming, 
 a distributed system is \emph{declaratively} described, 
 in terms of components and admissible interactions \emph{in a single code base}.
%
In particular, in type-level multi-tier programming, 
 the specification leverages the type system of the language to ensure the correctness and coherence of the architecture;
moreover, 
 it also relieves the developer from low-level concerns 
 by offloading to the compiler
 the responsibility of breaking the computation into deployment units %peers, 
 enforcing the contract defined in the code.
%

The integration of these two paradigms offers a promising strategy for designing and implementing \acp{cpsw} 
 that operates independently of the underlying infrastructure. 
 In this chapter, we explore this approach by combining ScaFi and ScalaLoci---a Scala-based framework for multitier programming.
\section{Background}
\label{background}
\subsection{Pulverized aggregate computing}

\tikzset{-,
  host/.style={rectangle,draw,line width={2pt},inner sep=10pt,
  	outer sep=0, minimum height=1.5cm, minimum width=1.8cm, %text height=0.2cm, 
  	text depth=0.5cm,
  	fill=black!10!white
  },
  node/.style={rectangle,draw,dotted,line width={1pt}, inner sep=2pt, 
  	fill=blue!20!white,
  	font=\large
  },
  nodeA/.style={node,fill=red!20!white},
  nodeB/.style={node,fill=green!20!white},
  nodeC/.style={node,fill=black!30!white},
  nodeD/.style={node,fill=white!20!white},
  plink/.style={line width=2pt},
  llink/.style={dotted,line width=2pt,red},
  hostThin/.style={rectangle,draw,line width={0.5pt},inner sep=10pt,
  	outer sep=0, minimum height=1.1cm, minimum width=1.8cm, %text height=0.2cm, 
  	text depth=0.5cm,
  	fill=black!10!white
  },
  lnode/.style={node,minimum width=0.55cm,minimum height=0.55cm},
  loglink/.style={->,line width=1.5pt}
}
\def\nm{0.35cm} %nm = node margin offset
\def\tpscale{0.8}
\newcommand{\agent}{node}
\renewcommand{\boldsymbol}[1]{\mathbf{#1}}
\newcommand{\LSens}{\boldsymbol{S}}
\newcommand{\LComp}{\boldsymbol{B}}
\newcommand{\LComm}{\boldsymbol{C}}
\newcommand{\LAct}{\boldsymbol{A}}
\newcommand{\LState}{\boldsymbol{K}}
At the core of pulverization~\cite{DBLP:journals/fi/CasadeiPPVW20} is the idea that the functional behaviour of a distributed application is fundamentally orthogonal to the actual deployment of the services that compose it.
%
Thus, through a classic \emph{divide-and-conquer} approach, in a pulverized system, 
 any \emph{logical device} (of the many composing the \ac{cpsw}) 
 is broken down into five \emph{components} acting as \emph{units of deployment}:
\begin{enumerate*}
 \item \emph{Sensors ($\LSens$)}, encapsulating the ability to retrieve information from the environment;
 \item \emph{Actuators ($\LAct$)}, responsible for acting upon the environment;
 \item \emph{State ($\LState$)}, providing persistence of knowledge;
 \item \emph{Behaviour ($\LComp$)}, modelling the actual execution of the application business logic; and
 \item \emph{Communication ($\LComm$)}, which provides means to interact with other logical devices.
\end{enumerate*}
%
These pulverized components can be deployed to different physical nodes of the network:
 as far as they can communicate with each other
 and the target execution protocol is respected,
 the functionality should not be affected.
%
Then, 
 a concrete development approach
 will expose abstractions
 with a well-defined mapping
 to such a partitioning schema.
%
So, an application designer can focus on functional requirements 
 while delaying all the deployment and communication concerns 
 (which may well affect non-functional properties of the system) 
 to a later moment. 

This strategy is especially well-suited to adapt approaches designed to work with a flat (non-layered) network structure (e.g., peer-to-peer, mesh, and ad-hoc networks) 
 to arbitrary network architectures---to exploit a broader range of deployments, e.g. for efficiency or reliability.
%
Consider, for instance, the simple case of
\Cref{img:p2p}:
 there is a 1:1 mapping between logical and physical devices, 
 and direct communication among devices (actually, among their $\LComm$ pulverized components) must be possible.
%
This is typically not the case in many Internet applications, however:
 let us consider the case in which the same application should be deployed in an IoT scenario where end devices are \emph{thin},
 equipped with sensors and actuators, but battery-powered and equipped with a microcontroller with minimal computational capabilities
(for instance, LoRaWAN or Sigfox motes~\cite{MekkiBCM18}).
%
These devices cannot host the actual computation of the program 
 (component $\LComp$), which must necessarily be offloaded to the edge of the cloud.
%
This change in the deployment would typically imply a re-writing of the functional logic of the program,
 as end devices cannot be considered computation-capable nodes any more.
%
Instead, with pulverization, they retain their existence as logical devices
 with some of their pulverized components hosted on different physical nodes as depicted in
\Cref{img:thin}.
%
Crucially, this makes the original application work on a different network architecture without any functional logic changes.

Aggregate computing is a naturally pulverizable approach:
 its semantics can be expressed as a purely functional manipulation of state, messages, and sensor readings~\cite{DBLP:journals/jlap/ViroliBDACP19},
 providing a straightforward mapping into pulverized components.
%
Indeed, initial experiments~\cite{DBLP:journals/fi/CasadeiPPVW20}
showed that aggregate programs deployed on pulverized infrastructures retain their original functional behaviour on different deployments.
%
Nevertheless, pulverization is not a silver bullet:
 the approach is fundamentally an engineering pattern to encapsulate a non-functional concern
 (network structure and deployment),
 allowing for the business logic to work across deployments,
 but it does not specify \emph{how} 
 a pulverized architecture should be described
 and verified so that it can be operated correctly at runtime.

\subsection{Multi-tier programming and \scalaloci{}}
The concrete architecture of a distributed system is usually \emph{multi-tier}, i.e.,
 it comprises multiple layers, each one encapsulating some specific functional concern 
 (e.g. data management, application and presentation logic, etc.)
 each physically separated from the others.
%
Historically, distinct tiers and crosscutting functionalities that belong to multiple tiers are developed into several compilation units 
 (often using different programming languages), 
 raising development and maintenance costs.

A recent trend in trying to tackle these issues is 
 \emph{multi-tier programming}~\cite{DBLP:journals/csur/WeisenburgerWS20},
 by which a distributed architecture is defined in a single compilation unit with a single language.
%
Once the program is declaratively specified,
 the compiler (or the runtime, depending on the language of choice) is responsible for
 splitting the computation among different peers.
%
Depending on the specific multi-tier programming language,
 different kinds of constraints may be imposed.
%
For instance, in Links~\cite{DBLP:conf/fmco/CooperLWY06},
 applications must follow a client-server architecture,
 while other languages allow for more freedom of choice.

One interesting language that lets the designer specify arbitrary deployments is \scalaloci{}
 ~\cite{Weisenburger.2018, DBLP:conf/ecoop/WeisenburgerS19, DBLP:journals/programming/WeisenburgerS20},
 a type-safe multi-tier language hosted in Scala language.
%
The structure of a \scalaloci{} application is defined through \textit{peers} and \textit{ties}.
%
Peers abstract over locations and represent the components
 of an application,
 whereas ties define the connections between peers. 
 Only tied peers can communicate with each other.

The following code depicts a simple controller-worker architecture.
%
Annotation \scalainline{@multitier} denotes the \scalainline{BookingApp} as a \scalaloci{} object. 

\begin{lstlisting}
/* Defines an application with the peers 'Controller' and 
 * and 'Worker' and a 1:n connection between them */
@multitier object BookingApp {
  @peer type Controller <: { 
    type Tie <: Multiple[Worker] 
  }
  @peer type Worker <: { 
    type Tie <: Single[Controller] 
  }
  on[Controller]{ print("I am a Controller") }
  on[Worker]{ print("I am a Worker") }
}
\end{lstlisting}
A declared \scalainline{@peer} type can have multiple instances that execute the peer's logic, 
 e.g., multiple worker instances.
%
In this example, 
 the logic is replaced with simple prints.
%
An instance of the controller peer may connect to multiple workers, 
 whereas a worker instance is tied to one controller. 
%
The sample compiles two executables representing the controller and the worker, 
 whose instances can be deployed and executed on different physical nodes.
\begin{lstlisting}
/* accessible for workers. */
val requests: Event[Request] on Controller = placed {...}
// Name of the worker @Worker accessible for Controller.
val name: String on Worker = placed {...}
/* not accesible for workers. */
val tokens : Local[Map[Long]] on Controller = 
  placed {...}
/* Access allowed: Worker observes events 
   emitted on Controller. */
on[Worker]{ requests.asLocal.observe{...} }
// Error: no access to tokens outside of the Controller.
on[Worker]{ tokens.asLocal.observe{...} }
\end{lstlisting}

Asynchronous multi-tier reactives like signals and events are used to compose non-blocking data flows that span across multiple peers. 
%
Data from remote peers are accessed using \scalaloci{}'s \scalainline{.asLocal} expression variants,
 and the visibility of placement types for remote peers can be regulated.
%
A \scalainline{@multitier} module can capture the controller-worker schema:
\begin{lstlisting}
@multitier trait ControllerWorker[T] {
  @peer type Controller <: { 
    type Tie <: Multiple[Worker]
  }
  @peer type Worker <: { 
    type Tie <: Single[Controller] 
  }
  def run(task: Task[T]): Future[T] on Controller =
    // run task on some selected worker
    on(selectWorker()) // (`selectWorker` is left out) 
      .run.capture(task) { task.process() }.asLocal
}
\end{lstlisting}
The \scalainline{run} method has return type as the placement type \scalainline{Future[T] on Controller}\footnote{Scala enables infix use of binary type constructors;  i.e., \mintinline[fontsize=\scriptsize]{scala}{A on B} refers to the same type as \mintinline[fontsize=\scriptsize]{scala}{on[A,B]}.}, effectively placing \scalainline{run} on the \scalainline{Controller} peer. 
%
The \scalainline{Task} type is parametrized over the type \scalainline{T} of the value, which a task produces after execution. 
%
Running a remote task remotely results in a \scalainline{Future} to account for processing time network delays and potential failures. 
%
The remote block is executed on the worker, which starts processing the task. 
%
The remote result is transferred back to the controller as \scalainline{Future[T]} using \scalainline{asLocal}. 
%
A single worker instance in a pool of workers is selected for processing the task via the \scalainline{selectWorker} method. 

The module can be used to implement an application where a server offloads work
 to the connected clients. In the following code, 
we specialize the clients to be workers and the server to be a controller:

\begin{lstlisting}
@multitier trait VolunteerProcessing {
  val m: ControllerWorker[Int] // ref to another module
  // augmenting the peers in this module
  @peer type Client <: m.Worker
  // with the controller/worker functionality
  @peer type Server <: m.Controller    
  on[Server] { m.run(new Task()) }
}
\end{lstlisting}

\section{Multi-tier pulverised aggregate computing}
\label{multitier+pulverisation}

The contribution of this work is an architecture for multi-tiered deployment strategies in pulverized systems,
along with a prototypical implementation using aggregate programming and \scalaloci{}.
% 
Using multi-tier abstractions, we: 
\begin{enumerate}
  \item map the overall logical system into a multi-tiered module, building the concept of a pulverized device into \scalaloci{} (see \Cref{code:loci:pulverised});
  \item define the functions associated with each pulverized component;
  \item characterize the possible kinds of network nodes (e.g., cloud, edge, thin-end device);
  \item decide the network structure in terms of possible connections among network node kinds;
  \item detail the deployment by assigning each pulverized component to a network node kind. 
\end{enumerate}
Ultimately, 
 this architectural design allows us to specify functional behaviour independently of deployment
 (via pulverized aggregate programming),
 then declaratively define multiple deployment schemes and their related communication constraints
 (thanks to multi-tier programming),
 and finally, statically enforce the respect of the expressed constraints
 (as a consequence of the robust type programming system introduced by \scalaloci{}).

\subsection{Pulverized architecture in \scalaloci{}}
\input{papers/ecas2021/pulverised.tex}
As a first step, 
 we need to formalize what a pulverized architecture is in \scalaloci{},
 by defining all the pulverized components and binding them together into the concept of the logic node.
%
\Cref{img:pulverised-loci} shows a possible \scalaloci{} implementation (\Cref{code:loci:pulverised}) 
 of a pulverized device (\Cref{fig:pulv:dev}):
\scalainline{LNode} represents the logical device,
\scalainline{LogicalSystem} encloses the concept of the pulverized system into a multi-tier module.
%
The logical device and all its pulverized components are mapped on abstract peers.

Once all components are modelled,
 their contract must be specified to characterize them and define their behaviour.
%
This is done by \emph{placing} the available computations on the components that will effectively host them.
%
For instance, 
 if our system has the notion of \scalainline{Sensor[V]},
 representing a generic sensor that upon access returns values of type \scalainline{V},
 we can enforce the requirement that the \scalainline{SensorComponent} must be able to read values from sensors via something like: 
\begin{lstlisting}
def sense[V](id: SensorID): V on SensorComponent = ...
\end{lstlisting}
%
This strategy decouples the \emph{structural} definition of components participating in the system from their \emph{behavioural} specification.

\subsection{Definition of deployment kinds}
\input{papers/ecas2021/deployments}

Once the definition of components is complete, we can begin describing the actual deployments.
%
These can be expressed rather concisely with the proposed design, 
 as depicted in \Cref{fig:pulv}, where we show three possible definitions of very different architectures.
%
In \Cref{img:p2p}, we define a system where logical and physical devices coincide.
%
This structure is typical of opportunistic network structures (P2P overlays, tactical networks, etc.).
%
\Cref{img:broker}, shows a hybrid edge-cloud system supporting the computation of \emph{thick} end devices (e.g., smartphones).
%
The infrastructure hosts the communication components,
 de facto enabling network communication among end devices
 (this is a typical situation in usual Wi-Fi networks, where end devices are ``hidden'' a router performing network address translation).
%
A practical example of this architecture could be a multi-broker MQTT system,
 with brokers deployed either on the edge
 (for better performance with closely located devices)
 or on the cloud.
%
Finally, in \Cref{img:thin}, we replicate a similar system, but with \emph{thin} end devices.
%
Namely, end devices do not possess enough computational capacity to host their associated computation
and thus need to operate as remote sensors and offload all calculations to an external device.
%
This situation is typical of WAN sensing networks (e.g., LoRaWAN),
 where end devices are equipped with minimal memory and very low-power microcontrollers
 and are expected to run on battery for years.
%
To summarize, different network architectures can be specified by following two steps:
\begin{enumerate*}
 \item definition of the physical devices involved in the architecture and how they are \emph{tied} together; and
 \item allocation of the pulverized components on the kinds of devices that can host them.
\end{enumerate*}

The resulting system can then be instanced by selecting a communication protocol and a serialization framework.
%
For example, in the following snippet, 
 we show how this could be done for the system in \Cref{img:broker}, 
 assuming communication via TCP and serialization via the uPickle library.

\begin{lstlisting}
import loci.serializer.upickle._ // Serialization logic
import loci.communicator.tcp._ // Communication protocol
object Broker extends App { // Peer instatiation
  val tie = listen[BrokerBased.Peer](TCP(port))
  multitier.start(new Instance[BrokerBased.Broker](tie))
}
object Peer extends App {
  val tie = connect[BrokerBased.Broker](TCP(host, port))
  multitier.start(new Instance[BrokerBased.Node](tie))
}
\end{lstlisting}

\subsection{Integration with aggregate programming}
\label{scafiloci}
The design described so far is entirely independent of the specific aggregate programming language of choice:
 due to pulverization, the way the logic is expressed only concerns the behavioural component ($\LComp$).
%
As reference aggregate computing library we picked \scafi{} for our prototype,
 mainly because it shares the language of choice with \scalaloci{},
 and thus it could be the foundation stone of a unified framework living in the Scala ecosystem.  
 A full account of \scafi{} can be found in~\Cref{part:background}.

To perform a collective computation, 
 \scafi{} requires to define an \scalainline{AggregateProgram} 
  (i.e. an object containing the aggregate application logic) and 
 a \scalainline{Context} (i.e., the set of information required to evaluate an \scalainline{AggregateProgram}, 
 such as the previous state, sensors' data, and messages received from neighbours).
%
\scafi{}'s \scalainline{Context}s in a pulverized architecture are embedded in the \scalainline{State} component.
%
Consequently, the glue code required to execute \scafi{} aggregate code over a pulverized network is minimal:
\begin{lstlisting}
def compute(
  deviceIdentifier: Id,
  state: State
): State on BehaviourComponent = {
  val context = new ContextImpl(
    deviceIdentifier,
    export = state.exports,
    localSensor = state.sensors,
    neighbourSensor = state.neighbourSensor
  )
  val program : AggregateProgram = ... // business logic
  // actual execution; returns the new State
  program.round(context)
}
\end{lstlisting}
\section{Implications}
\label{implicitation}
The construction of a pulverized platform for aggregate computing via multi-tier programming introduces a plethora of intriguing applications, 
 each with its unique impact and significance. 
 In this section, we delve deeper into these applications, 
 examining their technical intricacies and their broader implications for both academia and industry.

\paragraph*{Programmability and Compile-Time Safety in Deployment Architectures for Pulverized Systems}
The use of type-annotated definitions in the deployment of a pulverized system confers robustness and reliability to the architectural integrity of the system. 
 This approach facilitates static consistency checks between the planned architecture and its deployed instantiation, 
 enabling the compiler to enforce constraints. 
 As a result, unauthorized access to data that is not within the scope of a specific component is precluded by design. 
 This dramatically enhances system security and diminishes runtime errors. 

From an engineering standpoint, 
 the focus then squarely shifts to addressing the functional aspects of the application. 
 In this context, the functional aspect refers to crafting the core logic of an aggregate computing program. 
 We posit that this approach can be subsumed under a broader research paradigm aimed at modularizing functional and non-functional concerns. 
 The latter could then be managed using specialized techniques and languages tailored for those specific challenges.

\paragraph*{Opportunistic Deployment and Dynamic Reconfiguration of Pulverized Systems}
The inherent flexibility of the pulverized architecture enables dynamic adaptability in application deployment. 
 Essentially, it is conceivable to reposition components of a logical device across multiple physical nodes dynamically. 
 For instance, a $\LComp$ component could be offloaded to the cloud to conserve battery life on the original device. 
 While this concept is conceptually supported by the pulverization methodology, its practical implementation is currently limited due to \scalaloci{}'s focus on static data placement.

Nonetheless, 
 our research opens the door to future developments that could extend existing languages to support dynamic data placement between peers. 
 Such an extension would not only augment system flexibility but also maintain type safety in the system specification.

\paragraph*{Incorporation of Placement Types in aggregate programming}
As it stands, \scalaloci{} and \scafi{} have been designed to function in tandem in such a way that the aggregate program remains blissfully unaware of its multi-tier deployment architecture. 
 However, another avenue for exploration is how placement types, 
 along with other novelties introduced by \scalaloci{}'s unique take on multi-tier programming, 
 could be strategically utilized within aggregate computing systems.

At present, the specific implications and potential benefits of manipulating placement types at the level of aggregate computing are not yet fully understood. 
 Nonetheless, we see emerging opportunities for developing adaptive networked systems capable of dynamic evolution. 
 These preliminary insights suggest a fertile ground for further research and development in this area.

\section{Final remarks}
\label{conclusion}

In this chapter, 
 we introduce a methodology for bridging fragmented architectures with the verified deployment of aggregate systems. 
 We utilize multitier programming to enhance declaratively, expressiveness, and safety. 
 Specifically, we demonstrate how to define a fragmented architecture using ScalaLoci and then map it to an actual deployment.

Additionally, we outline how aggregate computations can be seamlessly integrated into the existing infrastructure. 
 This is achieved by sketching the implementation of the system's behavioural aspects using the \scafi{} aggregate computing toolkit.

Given the vast design possibilities in this context, 
 we posit that the synergy between multitier programming and fragmented aggregate programming presents a compelling strategy for designing and implementing \ac{cpsw}. 
 This approach allows for independent operation from the underlying infrastructure while maintaining the integrity of the business logic.
